{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LxWgkyiKOSRC1Cv1wA70_02BC3Q-fqu5",
      "authorship_tag": "ABX9TyN9jBR89MKkiABXL5z4sOxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MAKKAJIYASHASREE/NLP-PROJECT/blob/main/Mcq_generation_without_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ogwf_rOiwXHW"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/egypt.txt','r') as f:\n",
        "     summary = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/boudinfl/pke.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2g39PMJwg8i",
        "outputId": "c32b7ece-97ef-4ef7-ac8f-6c2c4e25caa3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/boudinfl/pke.git\n",
            "  Cloning https://github.com/boudinfl/pke.git to /tmp/pip-req-build-aikfvaua\n",
            "  Running command git clone -q https://github.com/boudinfl/pke.git /tmp/pip-req-build-aikfvaua\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (3.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (2.6.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (1.7.3)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (1.2.0)\n",
            "Requirement already satisfied: spacy>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pke==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.10)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.0.8)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.4.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (8.1.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (0.6.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.10.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.11.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.4.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.3->pke==2.0.0) (2.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.3->pke==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.2.3->pke==2.0.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.3->pke==2.0.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke==2.0.0) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.3->pke==2.0.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.3->pke==2.0.0) (0.0.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.2.3->pke==2.0.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.3->pke==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pke==2.0.0) (2022.6.2)\n",
            "Building wheels for collected packages: pke, sklearn\n",
            "  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pke: filename=pke-2.0.0-py3-none-any.whl size=6160277 sha256=ee7d812a5244866024701ce51af3bf11c1796b09ef396ea2068c553e2afab947\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jvry_igx/wheels/fa/b3/09/612ee93bf3ee4164bcd5783e742942cdfc892a86039d3e0a33\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=6adc6c2a6b1aff49381967bab3bb2ac4c609cd710925e87bf204a93d92e332aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
            "Successfully built pke sklearn\n",
            "Installing collected packages: unidecode, sklearn, pke\n",
            "Successfully installed pke-2.0.0 sklearn-0.0.post1 unidecode-1.3.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfgroZAVw7Tm",
        "outputId": "94a26b2c-7a98-422b-b4fc-d3abba62a607"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import pke\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def extracting_keywords(summary):\n",
        "    keywords = []\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    stoplist = list(string.punctuation)\n",
        "    stoplist+= stopwords.words('english')\n",
        "    stoplist+= ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "    extractor.load_document(summary,stoplist=stoplist)\n",
        "    pos = {'PROPN'}\n",
        "    extractor.candidate_selection(pos=pos)\n",
        "   \n",
        "    extractor.candidate_weighting()\n",
        "    keyphrases = extractor.get_n_best(n=15)\n",
        "    for i in keyphrases:\n",
        "        keywords.append(i[0])\n",
        "    return keywords\n",
        "\n",
        "key=extracting_keywords(summary)\n",
        "print(key)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMbThNw2lQ83",
        "outputId": "253dfb8e-bdb9-4aa7-f135-abd01acd5127"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/language.py:1899: UserWarning: [W123] Argument disable with value ['ner', 'textcat', 'parser'] is used instead of ['senter'] as specified in the config. Be aware that this might affect other components in your pipeline.\n",
            "  config_value=config[\"nlp\"][key],\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['egyptians', 'nile river', 'egypt', 'nile', 'euphrates', 'tigris', 'old kingdom', 'red land', 'double crown', 'narmer', 'upper', 'longest river', 'crown', 'africa', 'mediterranean sea']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flashtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxK-4M5zx5tG",
        "outputId": "8917b95c-3bb5-4cc7-f4ac-6fc861fc798f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9309 sha256=7bf32d98accba81eb39298187a356ad4334a0a8da86eb0855af418c6b9c85768\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext\n",
            "Successfully installed flashtext-2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjqnCTD3x-iK",
        "outputId": "b215ce8e-55d6-4a07-8744-c92cb9758576"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = [sent_tokenize(text)]\n",
        "    sentences = [y for x in sentences for y in x]\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_sentences_for_keyword(key, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in key:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "sentences = tokenize_sentences(summary)\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(key, sentences)\n",
        "        \n",
        "print (keyword_sentence_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1hGjPkeFFmd",
        "outputId": "082126f8-f388-42f5-b2f4-d777f50377ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'egyptians': ['Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.', 'These beautiful blue stones were used in jewelry.The Nile had fish and other wildlife that Egyptians wanted.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records.', 'Egyptian Houses Egyptians built houses using bricks made of mud from the Nile mixed with chopped straw.', 'Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife.', 'The Egyptians also developed a paperlike material called papyrus papyrus from a reed of the same name.', 'Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy.', 'Their army conquered by using better weapons and horse-drawn chariots, which were new to Egyptians.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'This prosperity made life easier and provided greater opportunities for many Egyptians.', 'The ancient Egyptians thought the pharaoh was a child of the gods and a god himself.', 'After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.', 'Beginning about 3000 B.C., Egyptians developed a writing system using hieroglyphs.', 'To go on the river, Egyptians made lightweight rafts by binding together reeds.', 'The Egyptians wanted valuable metals that were not found in the black land.', 'Egyptians created a government that divided the empire into 42 provinces.', 'Egyptians believed that if the gods were angry, the Nile would not flood.', 'A few Egyptians traveled to the upper Nile to trade with other Africans.', 'Based on that, Egyptians developed the world’s first practical calendar.', 'Geometric shapes such as squares and triangles were sacred to Egyptians.', 'Early Egyptians created a hieroglyphic system with about 700 characters.', 'Eventually, Egyptians equipped their reed boats with sails and oars.', 'Poorer Egyptians simply went to the roof to cool off after sunset.', 'Almost all Egyptians married when they were in their early teens.', 'Egyptians often painted walls white to reflect the blazing heat.', 'Egyptian Crops Ancient Egyptians grew a large variety of foods.', 'Ancient Egyptians also desired gold for its bright beauty.', 'For these reasons, early Egyptians stayed close to home.', 'Most Egyptians slept on mats covered with linen sheets.', 'With them, Egyptians created some of the first books.', 'Egyptians also grew the materials for their clothes.', 'The Egyptians developed some of the first geometry.', 'Egyptians looked for copper as early as 6000 B.C.', 'Eventually, Egyptians stopped building pyramids.', 'Egyptians also wove marsh grasses into sandals.', 'An estimated 20,000 Egyptians worked on it.', 'Egyptians also captured quail with nets.', 'The Egyptians also mined lapis lazuli.', 'Egyptians mined precious stones too.'], 'nile river': ['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.', 'The Nile River fed Egyptian civilization for hundreds of years.'], 'egypt': ['As in many ancient societies, much of the knowledge of Egypt came about as priests studied the world to find ways to please the gods.', 'Veins (long streaks) of copper, iron, and bronze were hidden inside desert mountains in the hot Sinai Peninsula, east of Egypt.', 'Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'If Egypt suffered hard times for a long period, the people blamed the pharaoh for angering the gods.', 'For about 500 more years, the kings held Egypt together, but with a much weaker central government.', 'In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war.', 'Children in Egypt played with toys such as dolls, animal figures, board games, and marbles.', 'The first rulers of Egypt were often buried in an underground tomb topped by mud brick.', 'Ancient Egypt had no money, so people exchanged goods that they grew or made.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'Rulers during the Middle Kingdom also faced challenges from outside Egypt.', 'Egypt was one of the best places in the ancient world to be a woman.', 'A nomadic people called the Hyksos invaded Egypt from the northeast.', 'Legend says a king named Narmer united Upper and Lower Egypt.', 'After Egypt was united, its ruler wore the Double Crown.', 'The king of Egypt became known as the pharaoh pharaoh.', 'One of the highest jobs in Egypt was to be a priest.', 'The parts of Egypt not near the Nile were a desert.', 'Weather in Egypt was almost always the same.', 'Egypt also created an army to defend itself.', 'As Egypt grew, so did its need to organize.', 'More than 30 dynasties ruled ancient Egypt.', 'Egypt’s economy depended on farming.', 'Egypt prospered along the Nile.'], 'nile': ['About 5,000 years ago, they noticed that a star now called Sirius appeared shortly before the Nile began to flood.', 'These beautiful blue stones were used in jewelry.The Nile had fish and other wildlife that Egyptians wanted.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'Egyptian Houses Egyptians built houses using bricks made of mud from the Nile mixed with chopped straw.', 'Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'Farmers did the heavy labor of hauling stone during the season when the Nile flooded their fields.', 'The river is called the upper Nile in the south and the lower Nile in the north.', 'The river is called the upper Nile in the south and the lower Nile in the north.', 'More adventurous hunters speared hippopotamuses and crocodiles along the Nile.', 'For centuries, heavy rains in Ethiopia caused the Nile to flood every summer.', 'The Longest River the Nile is 4,160 miles long—the world’s longest river.', 'Egyptians believed that if the gods were angry, the Nile would not flood.', 'A few Egyptians traveled to the upper Nile to trade with other Africans.', 'The burial chambers were hidden in mountains near the Nile.', 'Each year the Nile’s floods washed away land boundaries.', 'The floods deposited rich soil along the Nile’s shores.', 'The parts of Egypt not near the Nile were a desert.', 'In the delta, the Nile divides into many streams.', 'In the south the Nile churns with cataracts.', 'Near the sea the Nile branches into a delta.', 'The Nile then became a highway.', 'Egypt prospered along the Nile.'], 'euphrates': ['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.'], 'tigris': ['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.'], 'old kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'The Old Kingdom started about 2575 B.C., when the Egyptian empire was gaining strength.'], 'red land': ['Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'The red land was the barren desert beyond the fertile region.'], 'double crown': ['After Egypt was united, its ruler wore the Double Crown.'], 'narmer': ['Some historians think Narmer actually represents several kings who gradually joined the two lands.', 'Legend says a king named Narmer united Upper and Lower Egypt.'], 'upper': ['Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa.', 'The river is called the upper Nile in the south and the lower Nile in the north.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'A few Egyptians traveled to the upper Nile to trade with other Africans.', 'Legend says a king named Narmer united Upper and Lower Egypt.'], 'longest river': ['The Longest River the Nile is 4,160 miles long—the world’s longest river.', 'The Longest River the Nile is 4,160 miles long—the world’s longest river.'], 'crown': ['It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.', 'It combined the red Crown of Lower Egypt with the white Crown of Upper Egypt.'], 'africa': ['Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in Africa.', 'It begins near the equator in Africa and flows north to the Mediterranean Sea.'], 'mediterranean sea': ['It begins near the equator in Africa and flows north to the Mediterranean Sea.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pywsd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC7EwJa2yS_y",
        "outputId": "debc1339-3b59-439f-c157-c3230d1d0f0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pywsd\n",
            "  Downloading pywsd-1.2.5-py3-none-any.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 98.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.15.0)\n",
            "Collecting wn==0.0.23\n",
            "  Downloading wn-0.0.23.tar.gz (31.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.6 MB 113 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.3.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pywsd) (2022.6.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Building wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.23-py3-none-any.whl size=31792926 sha256=1a4558c412dc3d1a6f80f0a41324a26d32ed672b5d210988047b978cb7ba6920\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/47/17/409766c99dd470f34c512000b90b83f34747c2c975769654d7\n",
            "Successfully built wn\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.5 wn-0.0.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-tAPXekyW0z",
        "outputId": "f4ec9549-0ac7-4de9-8ba2-52fa08fc5f6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHW7SRbsyisv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from pywsd.similarity import max_similarity\n",
        "from pywsd.lesk import adapted_lesk\n",
        "from pywsd.lesk import simple_lesk\n",
        "from pywsd.lesk import cosine_lesk\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "# Distractors from Wordnet\n",
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0: \n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "def get_wordsense(sent,word):\n",
        "    word= word.lower()\n",
        "    \n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    \n",
        "    \n",
        "    synsets = wn.synsets(word,'n')\n",
        "    if synsets:\n",
        "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
        "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
        "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
        "        return synsets[lowest_index]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Distractors from http://conceptnet.io/\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = [] \n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term'] \n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "                   \n",
        "    return distractor_list\n",
        "\n",
        "key_distractor_list = {}\n",
        "\n",
        "for keyword in keyword_sentence_mapping:\n",
        "    wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "    if wordsense:\n",
        "        distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "        if len(distractors) ==0:\n",
        "            distractors = get_distractors_conceptnet(keyword)\n",
        "        if len(distractors) != 0:\n",
        "            key_distractor_list[keyword] = distractors\n",
        "    else:\n",
        "        \n",
        "        distractors = get_distractors_conceptnet(keyword)\n",
        "        if len(distractors) != 0:\n",
        "            key_distractor_list[keyword] = distractors\n",
        "\n",
        "index = 1\n",
        "for each in key_distractor_list:\n",
        "    sentence = keyword_sentence_mapping[each][0]\n",
        "    pattern = re.compile(each, re.IGNORECASE)\n",
        "    output = pattern.sub( \" _______ \", sentence)\n",
        "    print (\"%s)\"%(index),output)\n",
        "    choices = [each.capitalize()] + key_distractor_list[each]\n",
        "    top4choices = choices[:4]\n",
        "    random.shuffle(top4choices)\n",
        "    optionchoices = ['a','b','c','d']\n",
        "    for idx,choice in enumerate(top4choices):\n",
        "        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
        "    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
        "    index = index + 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBJ3VGCqFvmk",
        "outputId": "82da398c-28ba-48c7-977f-7027e479d3cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warming up PyWSD (takes ~10 secs)... took 7.6798789501190186 secs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1)  _______  cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.\n",
            "\t a )   Algerian\n",
            "\t b )   Angolan\n",
            "\t c )   Bantu\n",
            "\t d )   Egyptians\n",
            "\n",
            "More options:  ['Basotho', 'Beninese', 'Berber', 'Black African', 'Burundian', 'Cameroonian', 'Carthaginian', 'Chadian', 'Chewa', 'Congolese', 'Djiboutian', 'Egyptian', 'Ethiopian', 'Eurafrican', 'Ewe', 'Fulani'] \n",
            "\n",
            "\n",
            "2) As in many ancient societies, much of the knowledge of  _______  came about as priests studied the world to find ways to please the gods.\n",
            "\t a )   Saudi Arabia\n",
            "\t b )   Kuwait\n",
            "\t c )   Egypt\n",
            "\t d )   Iraq\n",
            "\n",
            "More options:  ['Jordan', 'Israel', 'Fertile Crescent', 'Turkey', 'Iran', 'Lebanon', 'Shari', 'Mauritania', 'Nigeria', 'Somali peninsula', 'Sierra Leone', 'Malawi', 'North Africa', 'Senegal', 'Mozambique', 'Lake Tanganyika'] \n",
            "\n",
            "\n",
            "3) About 5,000 years ago, they noticed that a star now called Sirius appeared shortly before the  _______  began to flood.\n",
            "\t a )   Gulu\n",
            "\t b )   Buganda\n",
            "\t c )   Nile\n",
            "\t d )   Entebbe\n",
            "\n",
            "More options:  ['Jinja', 'Lake Edward', 'kayunga', 'gulu', 'entebbe', 'Port Sudan', 'Omdurman', 'Darfur', 'Libyan Desert', 'Kordofan', 'Khartoum', 'Nubian Desert', 'Nyala', 'Aswan High Dam', 'Eastern Desert', 'Aswan'] \n",
            "\n",
            "\n",
            "4) Unlike the Tigris and  _______ , the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.\n",
            "\t a )   Edirne\n",
            "\t b )   Adana\n",
            "\t c )   Euphrates\n",
            "\t d )   Dardanelles\n",
            "\n",
            "More options:  ['Antalya', 'Tigris', 'Ararat', 'Sardis', 'Aegospotami', 'Seyhan', 'Kurdistan', 'Damascus', 'Aleppo', 'Syrian Desert', 'Al Ladhiqiyah', 'Halab', 'Kerbala', 'Basra', 'Iraqi Kurdistan', 'Assyria'] \n",
            "\n",
            "\n",
            "5) Unlike the  _______  and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.\n",
            "\t a )   Edirne\n",
            "\t b )   Tigris\n",
            "\t c )   Dardanelles\n",
            "\t d )   Euphrates\n",
            "\n",
            "More options:  ['Adana', 'Antalya', 'Ararat', 'Sardis', 'Aegospotami', 'Seyhan', 'Kurdistan', 'Damascus', 'Aleppo', 'Syrian Desert', 'Al Ladhiqiyah', 'Halab', 'Kerbala', 'Basra', 'Iraqi Kurdistan', 'Assyria'] \n",
            "\n",
            "\n",
            "6) Nubia was the Egyptian name for the area of the  _______  Nile that had the richest gold mines in Africa.\n",
            "\t a )   Lower Berth\n",
            "\t b )   Upper\n",
            "\t c )   Upper Berth\n",
            "\n",
            "More options:  [] \n",
            "\n",
            "\n",
            "7) It combined the red  _______  of Lower Egypt with the white  _______  of Upper Egypt.\n",
            "\t a )   Head\n",
            "\t b )   Masthead\n",
            "\t c )   Capital\n",
            "\t d )   Crown\n",
            "\n",
            "More options:  [] \n",
            "\n",
            "\n",
            "8) Nubia was the Egyptian name for the area of the upper Nile that had the richest gold mines in  _______ .\n",
            "\t a )   Australia\n",
            "\t b )   Eurasia\n",
            "\t c )   Africa\n",
            "\t d )   Old World\n",
            "\n",
            "More options:  [] \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}